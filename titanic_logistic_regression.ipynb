{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project : Titanic :  Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeClassifier, BaseDecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : Load and Inspect the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train dataset\n",
    "t_train = pd.read_csv('train.csv')\n",
    "# Load Test dataset\n",
    "t_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Check dataset summery of statistics\n",
    "t_train.info()\n",
    "print('---'*15)\n",
    "t_test.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setp : 3 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check status of survived person by PClass in train data set\n",
    "survived_by_pclass = t_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "survived_by_pclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check status of survived person by Sex in train data set\n",
    "survived_by_sex =  t_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "survived_by_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check status of survived person by Parch (parents/children aboard) in tain data set\n",
    "survived_by_Parch = t_train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "survived_by_Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_by_SibSp = t_train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "survived_by_SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogram for survived person, Pclass and Age\n",
    "\n",
    "plot = sns.FacetGrid(t_train, col='Survived', row='Pclass', height=2.5, aspect=2)\n",
    "plot.map(plt.hist,'Age', bins = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogram for survived person Em\n",
    "\n",
    "plot = sns.FacetGrid(t_train, col='Survived', row='Embarked', height=2.5, aspect=2)\n",
    "plot.map(sns.barplot,'Sex', 'Fare', errorbar = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Data Cleaning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we drop columns which one is not much impact on our model, like PassengerId and Cabin \n",
    "\n",
    "t_train = t_train.drop(['PassengerId', 'Cabin', 'Ticket'], axis=1)\n",
    "t_test = t_test.drop(['Cabin', 'Ticket'], axis=1)\n",
    "t_train = t_train.drop(['Name'], axis = 1)\n",
    "t_test = t_test.drop(['Name'], axis=1)\n",
    "# As per data statistics report we fill  null value in  train and test dataset\n",
    "t_train['Embarked'] = t_train['Embarked'].fillna(method ='ffill')\n",
    "\n",
    "t_train['Age'] = t_train['Age'].fillna(t_train['Age'].mean())\n",
    "\n",
    "t_test['Fare'] = t_test['Fare'].fillna(t_test['Fare'].mean())\n",
    "\n",
    "t_test['Age'] = t_test['Age'].fillna(t_test['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we change gender in binary 0 for female and 1  for male \n",
    "t_train['Sex'] = t_train['Sex'].replace({'female': 0, 'male' : 1 })\n",
    "t_test['Sex'] = t_test['Sex'].replace({'female': 0, 'male' : 1 })  \n",
    "## Embarked will change S =1, C =2, Q =3 \n",
    "t_train['Embarked'] = t_train['Embarked'].replace({'S': 1, 'C': 2, 'Q':3})\n",
    "t_test['Embarked'] =t_test['Embarked'].replace({'S': 1, 'C': 2, 'Q':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Split Data into Training  and Testing  Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We drop Survived Column from data set \n",
    "x_train = t_train.drop('Survived', axis = 1)\n",
    "y_train = t_train['Survived']\n",
    "## Drop PassengerTD column from test data set \n",
    "x_test = t_test.drop('PassengerId', axis = 1)\n",
    "x_train.shape, y_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Standardize and Normalize Feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## used stander scaler to fit data of x_train and x_test\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train[['Age', 'Fare']] = scaler.fit_transform(x_train[['Age', 'Fare']])\n",
    "x_test[['Age', 'Fare']] = scaler.fit_transform(x_test[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Build and Train Machine Learning  Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we take as data for Y test from Gender_submission_CSV for reference purpose \n",
    "y_test = pd.read_csv('gender_submission.csv')\n",
    "y_test = y_test.drop('PassengerId', axis = 1)\n",
    "\n",
    "## Define model to use\n",
    "model = {\n",
    "    'Logistic Regression' : LogisticRegression(),\n",
    "    'Support Vector Classification' : SVC(), \n",
    "    'Stochastic Gradient Descent_C' : SGDClassifier(),\n",
    "    'Multi-Layer Perception classifier' : MLPClassifier(),\n",
    "    'Decision Tree Classifier' : DecisionTreeClassifier(),\n",
    "    'Random Forest Classifier' : RandomForestClassifier(n_estimators= 3),\n",
    "    'K-Nearest Neighbors' : KNeighborsClassifier(n_neighbors=7),\n",
    "    'Gradient Boosting Classifier' : GradientBoostingClassifier()\n",
    "}\n",
    "score = []\n",
    "\n",
    "## We have define data set \n",
    "for model_name, model in model.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    score.append({'Model': model_name,\n",
    "                  'Training_Score' : model.score(x_train, y_train),\n",
    "                  'Accuracy_with_Gender ': accuracy_score(y_test, y_pred)\n",
    "                  })\n",
    "    \n",
    "score_df = pd.DataFrame(score)\n",
    "display(score_df)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Visualization of Model Accuracy and Training Model Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample score data in the format given\n",
    "score_df = pd.DataFrame(score)\n",
    "\n",
    "# Melt the DataFrame to a long format for `hue` usage\n",
    "melted_score_df = score_df.melt(id_vars=\"Model\", \n",
    "                                value_vars=[\"Training_Score\", \"Accuracy_with_Gender \"],\n",
    "                                var_name=\"Score_Type\", \n",
    "                                value_name=\"Score\")\n",
    "\n",
    "# Plot using hue for Training_Score and Accuracy_with_Gender\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Model\", y=\"Score\", hue=\"Score_Type\", data=melted_score_df, palette=[\"blue\", \"green\"])\n",
    "\n",
    "# Customize plot appearance\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Training Scores and Test Accuracy by Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "\n",
    "# Display legend and the plot\n",
    "plt.legend(title=\"Score Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
